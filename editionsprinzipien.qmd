---
title: "Editionsprinzipien"
---
## Aufbereitung des Briefkorpus - Editionsprinzipien
### Auswahl der Texte
Das in dieser Arbeit genutzte Briefkorpus entstammt den im Internetauftritt der Universität Leipzig als "Landsberger Archives" veröffentlichten Dokumenten aus dem Nachlass und Umfeld von Benno Landsberger.^[Ich bin Michael P. Streck zu Dank verpflichtet, der mir gestattet hat, die veröffentlichten Materialien im Rahmen meiner Arbeit zu nutzen. Alle Veröffentlichungsrechte liegen beim Altorientalischen Institut der Universität Leipzig und der Hebrew University Jerusalem.] Bei den in Leipzig aufbewahrten Dokumenten handelt es sich vorrangig um Briefe und Postkarten von und an Kolleg\*innen sowie Familienmitglieder. Briefumschläge zu den einzelnen Briefen liegen nicht vor. Insbesondere unter den in Jerusalem aufbewahrten Nachlassobjekten finden sich des Weiteren Manuskripte, Notizen und Fotos.^[@streck_landsberger_2024.] Briefbeigaben wie Drucke und Manuskripte sind ebenfalls nicht aufbewahrt worden.^[Zum Thema Briefbeigaben siehe beispielsweise @bohnenkamp_beilage_2013.] Die Dokumente sind als PDF-Dateien verfügbar gemacht. Zu einigen, insbesondere handschriftlich verfassten Briefen, liegt zudem eine Transkription im PDF-Format vor.

Im Rahmen dieser Arbeit werden die Briefe als Textgattung herangezogen.^[Da Postkarten eine andere Form der Erschließung erfordern, werden sie hier nicht mitberücksichtigt. Zur Edition von Postkarten siehe beispielsweise @greinert_paratextelemente_2020.] Diese werden weiter selektiert. Ausgehend von der Fragestellung der Arbeit, die auf eine fachhistoriographische Untersuchung abzielt, werden nur Briefe berücksichtigt, die Landsberger mit Fachkolleg\*innen ausgetauscht hat. Briefe an und von Familienmitgliedern werden nicht näher betrachtet. Ebenfalls nicht berücksichtigt werden im Nachlass Landsbergers verwahrte Briefe, die offensichtlich in Besitz Landsbergers gekommen sind, jedoch weder von ihm verfasst noch an ihn adressiert wurden.^[Hierbei handelt es sich um einen Brief von D. Prince an F. Delitzsch sowie einen Brief von E. Weidner an H. Zimmern, die im "Landsberger Archives" unter den in Jerusalem aufbewahrten Dokumenten unter den Nummern 21 und 22 zu finden sind.] Zudem sind zwei handschriftliche Briefe von C. Schoch an Landsberger nicht in das bearbeitete Briefkorpus eingeflossen, da die schlechte Bildqualität, in der sie zur Verfügung gestellt wurden, für ein HTR-Verfahren nicht ausreicht.^[Hierbei handelt es sich um das in Jerusalem aufbewahrte Dokument mit der Nummer 25.] Des Weiteren ist zu erwähnen, dass nicht alle Briefe, die im "Landsberger Archives" erwähnt sind, dort auch als Digitalisat veröffentlicht sind und somit auch nicht für diese Arbeit zur Verfügung standen.

Insgesamt wurde für diese Arbeit daher ein Korpus aus 69 Briefen zusammengestellt, auf das die im Nachfolgenden beschriebenen Editionsschritte angewendet wurden. Während einige Schritte wie die automatische Texterkennung, die Erhebung von Metadaten und die Erstellung eines TEI Headers auf dem Gesamtkorpus durchgeführt werden konnten, wurde die Annotation der Brieftexte nur an einzelnen Briefen erprobt.^[Für die Ergebnisse siehe [https://th-blaschke.github.io/landsberger.github.io/briefe.html](https://th-blaschke.github.io/landsberger.github.io/briefe.html). Für die bisher nur z.T. edierten Briefe, die die Grundlage für eine weitere Edition bieten können, siehe für die Faksimiles [https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/pdf](https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/pdf), für die im Grundgerüst in TEI kodierten Briefe [https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/tei](https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/tei), für die TXT-Dateien [https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/txt](https://github.com/th-blaschke/landsberger.github.io/tree/main/files/letters/txt).]

### Automatische Texterkennung
Bei der Auswahl eines Tools zur automatischen Texterkennung, um die im PDF-Format vorliegenden Briefe in Hand- und Schreibmaschinenschrift in eine maschinenlesbare Form als TXT-Datei umzuwandeln, waren zwei Kriterien ausschlaggebend. Zum einen war zu berücksichtigen, dass die auf der Internetseite der Universität Leipzig im "Landsberger Archives"^[@streck_landsberger_2024.] zur Verfügung gestellten PDF-Dateien nicht der Qualität entsprechen, die beispielsweise in den Praxisregeln zur Digitalisierung der DFG beschrieben sind.^[Siehe dazu Kapitel 3.2 Technische Parameter der digitalen Reproduktion in @altenhoner_dfg-praxisregeln_2023.] Die vorliegenden Briefseiten weisen für die automatische Texterkennung Herausforderungen auf: durchscheinendes Papier, was beidseitig beschrieben ist, so dass Text der Rückseite auf der Vorderseite durchscheint; vergilbtes Papier mit verblasster Schrift; Tintenkleckse; durchgestrichener und korrigierter Text; Notizen an den Seitenrändern; blasse Schrift aufgrund der Tatsache, dass bei mit der Schreibmaschine verfassten Briefen nur das Durchschlagpapier vorliegt und nicht der Originalbrief; "aus der Reihe tanzende" Buchstaben in den Schreibmaschinendurchschlägen; handschriftliche Notizen in mit der Schreibmaschine geschriebenen Briefen; unterschiedliche vormoderne Sprachen und Schriftarten innerhalb eines Briefes. Einige dieser Herausforderungen ließen sich durch die gute Qualität eines Scans der Briefseiten und einer Nachbearbeitung mit einem Bildbearbeitungsprogramm sicherlich mindern. Zugang zu den gescannten Bilddateien oder ein erneuter Scan des Materials war im Rahmen dieser Arbeit jedoch nicht vorhanden bzw. zu leisten. Um durch die Umwandlung der vorliegenden PDF-Dateien in Bilddateien nicht einen zusätzlichen Qualitätsverlust zu riskieren, war es daher notwendig, ein Tool zu wählen, das auch das PDF-Format unterstützt.^[Dies schloss beispielsweise die weit verbreitete Software Tesseract aus, mit der nur Bilddateien verarbeitet werden können ([https://tesseract-ocr.github.io/tessdoc/InputFormats.html](https://tesseract-ocr.github.io/tessdoc/InputFormats.html), letzter Zugriff 29.12.2023). Ein proprietäres Tool wie der ABBYY FineReader ([https://pdf.abbyy.com/de/](https://pdf.abbyy.com/de/), letzter Zugriff 29.12.2023.) erschien zumindest für das in Schreimaschinenschrift vorliegende Briefmaterial eine Option zu sein. Das Ergebnis der Texterkennung war jedoch von so schlechter Qualität, da die oben beschriebenen Herausforderungen dafür sorgten, dass Artefakte wie durchscheinende Schrift oder verschmierte Tinte vom Programm als Text eingestuft wurden, aber natürlich nicht sinnvoll erkannt werden konnten. Daher wurde die Nutzung auch dieses Tools verworfen.] Zum anderen erschien es sinnvoll, ein Tool zu nutzen, das sowohl für die Erkennung von maschinenschriftlichem Text (OCR) als auch handschriftlich verfasstem Text (HTR) geeignet ist. Auch wenn einige handschriftlich verfasste Briefe bereits von Mitarbeitenden des Altorientalischen Instituts der Universität Leipzig manuell transkribiert wurden^[[https://www.gkr.uni-leipzig.de/fileadmin/Fakult%C3%A4t_GKR/Altorientalisches_Institut/Dokumente/Brief_71.pdf](https://www.gkr.uni-leipzig.de/fileadmin/Fakult%C3%A4t_GKR/Altorientalisches_Institut/Dokumente/Brief_71.pdf), letzter Zugriff 29.12.2023. Da die transkribierten Texte ebenfalls im PDF-Format vorliegen, mussten diese ebenfalls ins TXT-Format überführt werden. Die Transkribierenden haben keine Regeln festgehalten, nach denen die Transkription durchgeführt wurde. Es scheinen Unterschiede im Umgang mit beispielsweise durchgestrichenen und korrigierten Textpassagen vorhanden zu sein. Der Aufbau der Briefe wurde in der Transkription ebenfalls nur bedingt berücksichtigt. Zeilentrennungen wurden nicht wiedergegeben, sondern getrennte Wörter als Fließtext zusammengeschrieben. Letztlich war die Umwandlung der bereits transkribierten Texte in ein TXT-Format nach einheitlichen Regeln daher ebenso zeitaufwendig wie bei den durch die automatische Texterkennung erstellten TXT-Dateien.], stand die Texterkennung einiger weiterer Briefe noch aus. Dies grenzte die Auswahl eines Tools auf zwei Optionen ein: Transkribus^[[https://readcoop.eu/transkribus/?sc=Transkribus](https://readcoop.eu/transkribus/?sc=Transkribus), letzter Zugriff 29.12.2023.] und OCR4all^[[https://www.ocr4all.org/](https://www.ocr4all.org/), letzter Zugriff 29.12.2023.]. Da das Ausgangsmaterial von 69 Briefen nicht ausreichte, um ein eigenes Texterkennungs-Modell insbesondere für die Handschriften zu trainieren^[Für das Training so eines Modells werden für Transkribus zwischen 5.000 und 15.000 Wörter (ca. 25-75 Seiten) benötigt, siehe dazu [https://readcoop.eu/de/transkribus/howto/how-to-train-a-handwritten-text-recognition-model-in-transkribus/](https://readcoop.eu/de/transkribus/howto/how-to-train-a-handwritten-text-recognition-model-in-transkribus/), letzter Zugriff 29.12.2023.], war das Ziel, ein bereits existierendes Modell zu finden, das ein ausreichendes Maß an korrekter Texterkennung ermöglicht und manuelle Nachkorrekturen in Grenzen hält. Letztlich stellte sich durch Ausprobieren der beiden Tools Transkribus als das für dieses Briefkorpus am effektivsten einzusetzende Tool heraus.^[Aus meiner subjektiven Perspektive ist diesbezüglich auch festzuhalten, dass mir die Entzifferung der Schrift einiger handschriftlicher Briefe kaum möglich war. Die Texterkennung dieser Handschriften durch Transkribus war aber letztlich so gut, dass ich mich durch den OCR generierten Text an die Handschrift gewöhnen und somit auch manuelle Nachkorrekturen durchführen konnte.] Für die mit der Schreibmaschine verfassten Briefe wurde das Modell *Transkribus print 0.3*^[[https://readcoop.eu/de/modelle/print-multi-language-danish-dutch-german-finnish-french-latin-swedish/](https://readcoop.eu/de/modelle/print-multi-language-danish-dutch-german-finnish-french-latin-swedish/), letzter Zugriff 29.12.2023.] genutzt, für die handschriftlichen Briefe das Modell *The Text Titan I*^[[https://readcoop.eu/de/introducing-transkribus-super-models-get-access-to-the-text-titan-i/](https://readcoop.eu/de/introducing-transkribus-super-models-get-access-to-the-text-titan-i/), letzter Zugriff 29.12.2023.].

Nach der automatischen Texterkennung und Überführung ins TXT-Format wurde eine manuelle Korrektur der OCR/HTR-Fehler vorgenommen. Des Weiteren war es notwendig, einige Entscheidungen bezüglich der Wiedergabe des Brieftextes zu treffen. Dabei wurde sich an folgenden Prinzipien orientiert, die z.T. aus pragmatischen Gründen für diese Arbeit gewählt wurden und im Rahmen eines größer angelegten Editionsprojekts überdacht werden müssten:

-   Schreibfehler, die im originalen Brieftext vorliegen, wurden nicht korrigiert, sondern wie im Original belassen.

-   Textstellen, die weder durch die automatische Texterkennung noch durch ein manuelles Nachprüfen entzifferbar waren, wurden mit [?] gekennzeichnet, wenn es sich um ein einzelnes Wort handelt, und mit [...?] wenn es sich um eine Abfolge von mehr als einem Wort handelt.^[Dies folgt dem Vorgehen der Alfred Escher Briefedition, @jung_digitale_2022 sub Editionsprinzipien.]

-   Im Originaltext fehlende Leerzeichen wurden ergänzt (z.B. S. 4 statt S.4). Zusätzliche Leerzeichen, die im Originaltext zwischen einem Wort und nachfolgender Interpunktion stehen, wurden entfernt (z.B. Herr! statt Herr !). Hintergrund dessen ist, dass im Weiteren verschiedene Textanalyse-Verfahren mithilfe von Python-Skripten durchgeführt wurden. Ein einheitlicher Umgang mit Leerzeichen erleichterte somit eine Wortzählung oder Identifizierung einzelner Wörter.

-   Zeilenumbrüche und Worttrennung am Ende von Zeilen wurden wie im Original beibehalten.

-   Wurden im Originaltext Wörter durchgestrichen und neu geschrieben, wurde dies nicht originalgetreu in der generierten TXT-Datei dargestellt, sondern die vom Schreibenden intendierte korrigierte Version übernommen. Zu begründen ist dieses Vorgehen damit, dass bei der Analyse eines Briefkorpus eine Betrachtung der Textgenese weniger bedeutsam erscheint als bei literarischen Texten. Eine automatisierte Textanalyse, die in diesem Rahmen ebenfalls stattfindet, würde durch den Versuch der Wiedergabe dieser Korrekturschritte erschwert.^[Zum Umgang mit Korrekturen im Text und der Relation zwischen Faksimile und ediertem Text siehe auch @frohlich_digitale_2023, 76-77.]

-   Nicht im Text festgehalten wurde bei mehrseitigen Briefen der Seitenwechsel oder die Angabe, auf welcher Briefseite man sich derzeit befindet, da auch dies eine automatisierte Textanalyse erschweren würde. Um dem Fehlen dieser Information entgegen zu wirken, kann durch ein Nebeneinanderlegen eines Bilddigitalisats des Briefes und des erfassten Brieftexts optisch die Einteilung in Briefseiten nachvollzogen werden.^[Siehe dagegen kritisch @strobel__2021, 155-157.]

-   Da es sich um ein Briefkorpus handelt, das einem wissenschaftlichen Austausch im Fach Altorientalistik diente, finden sich in den Texten vereinzelt handschriftliche Einfügungen von Keilschriftzeichen, hebräischer und phönizischer Schrift. Diese lassen sich schwer in ein TXT-Format überführen. Daher sind die betreffenden Stellen als {Keilschrift}, {Hebräisch}, {Phönizisch} markiert. Auch hier muss auf das Bilddigitalisat des Briefes für eine Ansicht der Schriftzeichen verwiesen werden.

-   Ausführliche handschriftliche Kommentare im Schreibmaschinentext oder Randnotizen in handschriftlichen Texten, die vom Schreibenden nachträglich eingefügt wurden, wurden in der erstellten TXT-Datei unter den eigentlichen Brieftext gesetzt und mit einer Markierung versehen, wie sie auch im Originaltext eingefügt wurde, um sie auf die Textstelle zu referenzieren. Bedauerlicherweise ist nicht in jedem Fall unterscheidbar, ob eine Notiz direkt im Schreibprozess oder zu einem späteren Zeitpunkt, womöglich von einer anderen Person, hinzugefügt wurde.

### Verwendung von Normdaten
Die Nutzung von Normdaten bietet für eine digitale Edition eine Reihe von Vorteilen: eine eindeutige Identifizierung von Entitäten (Personen, Orte, Organisationen, Werke etc.) und die Definition von Begriffen, die wiederum die Auffindbarkeit von Daten nach den FAIR-Prinzipien^[[https://www.go-fair.org/fair-principles/](https://www.go-fair.org/fair-principles/), letzter Zugriff 18.11.2023.] und ihre Verknüpfung mit anderen Datenquellen ermöglicht. Auch können automatisierte Auswertungen von Daten durch ihre eindeutige Identifizierbarmachung mit Normdaten durchgeführt werden.^[@stadler_normdateien_2012, 174-183; @strobel_digitale_2014, 153; @kuhner_anforderungen_2021, 22-23.] Für die Nutzung von Normdatenquellen existieren verschiedene Empfehlungen.^[Für eine Liste von Empfehlungen siehe beispielweise @kailus_handreichung_2023, 91-98.]

Im Rahmen dieser Arbeit mit einer fachhistoriographsichen Fragestellung ist bezüglich Normdaten zwischen zwei Kategorien zu unterscheiden. Zum einen gilt es, moderne Personen, Orte und Publikationen mit Normdaten anzureichern. Hierzu wurden maßgeblich drei Normdatenquellen herangezogen, nämlich Wikidata^[[https://www.wikidata.org/wiki/Wikidata:Main_Page](https://www.wikidata.org/wiki/Wikidata:Main_Page), letzter Zugriff 29.12.2023.], GeoNames^[[https://www.geonames.org/](https://www.geonames.org/), letzter Zugriff 29.01.2024.] und die GND^[[https://www.dnb.de/DE/Professionell/Standardisierung/GND/gnd_node.html](https://www.dnb.de/DE/Professionell/Standardisierung/GND/gnd_node.html), letzter Zugriff 29.12.2023.]. Auch wenn in anerkannten Leitlinien wie den Praxisregeln zur Digitalisierung der DFG in Bezug auf die Verknüpfung von Personennamen mit Normdaten ausschließlich die GND als Referenzquelle genannt wird^[@altenhoner_dfg-praxisregeln_2023, 8, 26.] und auch die *Handreichung für ein FAIRes Management kulturwissenschaftlicher Daten* darauf hinweist, dass Pflege und Ausbau von Wikidata nicht in einer klaren institutionellen Verantwortlichkeit liegen^[@kailus_handreichung_2023, 92.] und Wikidata als Datenquelle daher mit einer gewissen Vorsicht zu betrachten ist, lässt sich dennoch begründen, warum die Nutzung beider Normdatenquellen im Rahmen dieser Arbeit sinnvoll ist. Verschafft man sich auf Wikidata einen Überblick zu Personen, die als Altorientalist\*innen gelabelt werden (siehe dazu den Abschnitt [Kontextualisierung der Korrespondenz](index.qmd#kontextualisierung-der-korrespondenz)) und die potenziell Teil des wissenschaftlichen Umfelds von Landsberger gewesen sind (durch Briefkorrespondenz, gemeinsame Publikationen, Rezensionen etc.), wird deutlich, dass es sich um einen internationalen Personenkreis handelt, so dass dementsprechend nicht zu jeder einzelnen Person in der GND ein Eintrag zu finden ist. Wikidata bietet hier einen weiteren Spielraum und erfasst gleichzeitig auch internationale Normdaten zu einer Person (wie z.B. eine VIAF ID). Es gibt gleichzeitig jedoch auch andere Fälle, in denen der Bekanntheitsgrad von Wissenschaftler\*innen nicht über das nationale Wissenschaftsfeld hinausgeht und daher aufgrund einer in Deutschland getätigten Publikation nur ein Eintrag in der GND vorliegt, jedoch kein Eintrag auf Wikidata. Um beide Eventualitäten abzudecken, wurden daher insbesondere in den Metadaten sowohl die Wikidata ID als auch die GND ID eingefügt.

Zum anderen entstehen in Bezug auf die Annotation der Briefinhalte und ihre Verknüpfung mit Normdaten weitere Herausforderungen. Auch wenn in der Altorientalistik Initiativen existieren, die auf die Erarbeitung von kontrollierten Vokabularen hinarbeiten^[[https://cdli-gh.github.io/glow_vocabularies/](https://cdli-gh.github.io/glow_vocabularies/), letzter Zugriff 29.12.2023.], stehen diese Bemühungen noch in den Anfängen und sind noch nicht auf breiter Ebene in der Fachkultur etabliert. In Bezug auf altorientalische Personennamen, die in den Brieftexten diskutiert werden, muss daher ebenfalls auf Wikidata als Quelle zurückgegriffen werden. In Fällen, in denen es sich bei der erwähnten Person um einen bekannteren König handelt, ist die Wahrscheinlichkeit hoch, dass ein passender Wikidata-Eintrag existiert. Bei anderen altorientalischen Personen aus dem Alltagsleben trifft dies meist nicht zu. Was die Nennung von altorientalischen Ortsnamen angeht, bietet sich die Möglichkeit, auf den Gazetteer Pleiades^[[https://pleiades.stoa.org/](https://pleiades.stoa.org/), letzter Zugriff 30.12.2023.] zurückzugreifen, der von einer Citizen-Science-Community gepflegt wird und Informationen über antike Ortsnamen sammelt. Einzelne Keilschrifttexte, die in den Briefen diskutiert werden und anhand ihres Namens, ihrer Museumsnummer oder ihres Publikationsortes genannt werden, können mit den Einträgen in der Datenbank der *Cuneiform Digital Library Initiative*^[[https://cdli.mpiwg-berlin.mpg.de/](https://cdli.mpiwg-berlin.mpg.de/), letzter Zugriff 30.12.2023.] verknüpft werden, wo zusätzliche Informationen sowie Fotos und Kopien der Texte zur Verfügung gestellt werden. Um auch sumerische oder akkadische Wörter, deren Bedeutung im Briefkorpus diskutiert wird, referenzieren zu können, bedürfte es digitaler Wörterbücher, die eine stabile Zitierung ermöglichen. Diese sind in der Altorientalistik derzeit noch ein Desiderat.

Briefe als Textgattung transportieren oft Informationen, die nicht explizit formuliert und nur so weit erklärt sind, dass die den Brief empfangende Person diese versteht. Diese impliziten Informationen zu dekodieren und durch die Anreicherung mit Normdaten eindeutig identifizierbar zu machen, kann daher für Wissenschaftler\*innen, die ein Briefkorpus mit einem gewissen zeitlichen Abstand und außerhalb der Community analysieren, in der der Brief entstanden ist, eine Herausforderung darstellen. Die Bereitstellung des hier analysierten Briefkorpus im Webauftritt der Universität Leipzig geht bereits mit vereinzelten erklärenden Informationen zu Absender\*innen und Empfänger\*innen der Briefe sowie inhaltlichen Informationen einher.^[@streck_landsberger_2024.] Um die Arbeit mit den Briefen weiter zu erleichtern, wurden im Rahmen dieser Arbeit zwei Datensammlungen geschaffen.

Bei der ersten Datensammlung handelt es sich um Personennamen, die zu Landsbergers Lebzeiten die Altorientalistik-Fachcommunity ausmachten (für die Datensammlung siehe den Abschnitt [Kontextualisierung der Korrespondenz](index.qmd#kontextualisierung-der-korrespondenz)). Diese Liste bietet neben einer Darstellung der Fachcommunity gleichzeitig auch eine Möglichkeit, den potenziellen Personenkreis einzugrenzen, der in den Briefen erwähnt wird. Ist lediglich ein Nachname wie Schuster, Friedrich oder Pohl ohne genauere Angaben genannt, kann zuerst versucht werden, den Namen in diesem Personenkreis zu finden, bevor eine weitere Recherche nach der erwähnten Person stattfinden muss, was sich unter Umständen zu einer Suche nach der Nadel im Heuhaufen entwickeln kann, wenn nur wenige Angaben im Brief vorliegen. 

Die zweite Datensammlung in Form einer CSV-Datei^[[https://github.com/th-blaschke/landsberger.github.io/blob/main/files/landsberger_publications.csv](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/landsberger_publications.csv).] basiert auf einem 1974 publizierten Artikel von Anne Draffkorn Kilmer und Johannes Renger, der einen Überblick über die von Landsberger verfassten Publikationen bietet.^[@kilmer_bibliography_1974.] Der Artikel wurde wie auch das Briefkorpus mithilfe des Tools Transkribus (siehe den Abschnitt [Automatische Texterkennung](#automatische-texterkennung)) einem OCR-Verfahren unterzogen und die erstellte TXT-Datei manuell in Tabellenform umgewandelt. Die darin enthaltenen Namen von Autor\*innen, mit denen Landsberger kollaboriert oder sie rezensiert hat, wurden mit ihren zugehörigen Wikidata- und GND-Einträgen verknüpft. Titel und Publikationsreihen sowie Zeitschriften wurden, insoweit möglich, mit ihren GND-Einträgen oder, falls alternativ vorhanden, mit dem zugehörigen Wikidata-Eintrag verbunden. Dies geschah entweder manuell oder über den Reconciliation Service von OpenRefine^[[https://openrefine.org/docs/manual/reconciling](https://openrefine.org/docs/manual/reconciling), letzter Zugriff 30.12.2023.]. Die entstandene CSV-Datei bietet somit die Möglichkeit, Publikationen, an denen Landsberger mitgewirkt hat und auf die in den Briefen angespielt wird, leichter zu identifizieren. Beispielsweise dreht sich eine Vielzahl der Briefe, die zwischen Karl Friedrich Müller und Benno Landsberger ausgetauscht wurden, um die Publikation des ersten Bandes der Reihe *Materialien zum sumerischen Lexikon*.^[@landsberger_serie_1937.]

### Erhebung von Metadaten
Folgende Metadaten^[Für eine Liste von Metadaten, die einen Brief als einen Brief definieren können, siehe auch @bohn_woran_2021, 18.] wurden zusammengestellt^[[https://github.com/th-blaschke/landsberger.github.io/blob/main/files/metadata_letters.csv](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/metadata_letters.csv).], insoweit sie aus den Einzelbriefen ersichtlich wurden:

|**Erfasste Metadaten**|**Erklärung**|
|---|---|
|Dateiname|Die im Rahmen der Digitalisierung der Einzelbriefe entstehenden TXT- und XML-Dateien erfordern eine systematische Benennung. Die einzelnen Dateinamen setzen sich aus dem im Briefkopf genannten Datum sowie dem Nachnamen von Absender\*in und Empfänger\*in zusammen.|
|   |    |
|Landsberger Archives Signatur|Entspricht den auf den Seiten der Universität Leipzig im "Landsberger Archives"^[@streck_landsberger_2024.] vergebenen Nummern für die einzelnen Dokumente.|
|   |    |
|Datum (ISO 8601) // Datum (de)|Das im Briefkopf genannte Datum wird zum einen im Format JJJJ-MM-DD sowie dem in Deutschland meist gebräuchlichen Format DD.MM.JJJJ angegeben. Ersteres Format entspricht der ISO-Norm 8601 und ist damit ortsunabhängig und für automatisierte Abfragen leicht handhabbar.^[Zur Empfehlung für die Nutzung dieses Formats siehe beispielsweise auch @kailus_handreichung_2023, 96.] In dieser Arbeit ist es insbesondere für die Kodierung der Brieftexte in TEI relevant.|
|   |    |
|Absender\*in/Empfänger\*in // GND ID // Wikidata ID|Um eine einheitliche Schreibung und eindeutige Identifizierung von Personen zu erreichen, werden die Namen der Absender\*innen und Empfänger\*innen der Briefe gemäß des Labels wiedergegeben, das sich in ihrem jeweiligen Eintrag in Wikidata findet. Eine beteiligte Person ist nicht auf Wikidata aber in der GND zu finden und wird daher gemäß dieser Angaben bezeichnet. Zu zwei weiteren Personen existieren weder auf Wikidata noch in der GND Einträge. Insoweit vorhanden, wurden für alle Personen für eine eindeutige Referenzierbarkeit sowohl die Wikidata ID als auch die GND ID in der Metadatentabelle hinzugefügt.|
|   |    |
|Aufenthaltsort Absender\*in/Empfänger\*in // GeoNames ID|Der Aufenthaltsort der*s Absender\*in wurde gemäß der Nennung in den Briefen erfasst. Der Aufenthaltsort der\*s Empfänger\*in ist in den wenigstens Fällen aus den Briefen ersichtlich und daher nur vereinzelt eingetragen. Zur eindeutigen Referenzierbarkeit sind die Ortsnamen mit ihrer jeweiligen GeoNames ID erfasst.|
|   |    |
|Sprache // Sprache ID|Unter Sprache wird die Hauptsprache, in der die Briefe verfasst sind, angegeben (Deutsch, Englisch, Französisch). In einigen Briefen finden sich zusätzlich Passagen in altorientalischen Sprachen. Das Vorhandensein dieser Passagen wird jedoch nicht in den Metadaten erfasst, sondern mittels Annotation (siehe dazu den Abschnitt [TEI text/body](#tei-textbody)). Zur eindeutigen Referenzierbarkeit wird die Hauptsprache mit einem Identifier gemäß IANA versehen, wie es auch in den TEI Guidelines vorgeschlagen wird.^[[https://www.tei-c.org/release/doc/tei-p5-doc/en/html/CH.html#CHSH](https://www.tei-c.org/release/doc/tei-p5-doc/en/html/CH.html#CHSH), letzter Zugriff 29.12.2023.]|
|   |    |
|Schriftart|Dieses Feld enthält die Angabe, ob es sich um einen handschriftlich oder mit der Schreibmaschine verfassten Brief handelt. In Bezug auf Schreibmaschinentext wird zudem unterschieden, ob es sich um das Brieforiginal oder den Durchschlag handelt und ob handschriftliche Korrekturen und Notizen hinzugefügt wurden.|
|   |    |
|verwahrt von|Angabe, von welcher Institution bzw. Privatperson der jeweilige Brief aufbewahrt wird.| 
|   |    |
|Anzahl Seiten|Angabe der Anzahl von Seiten, die der Brief umfasst.^[Dies wurde mittels eines Python-Skriptes erfasst. Siehe dazu [https://github.com/th-blaschke/landsberger.github.io/blob/main/files/python/count_pages_words.py](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/python/count_pages_words.py).]|
|   |    |
|Anzahl Wörter|Angabe der Anzahl von Wörtern, die der Brief enthält (inklusive Datumszeile, Anschrift etc.).^[Für die Erfassung der Wortzahl mithilfe eines Python-Skriptes siehe die vorangehende Fußnote.]|
|   |    |
|Häufigste Wörter (Relative Häufigkeit)|Um eine einfache Zusammenfassung des Inhalts und Schwerpunkts der einzelnen Briefe zu ermöglichen, wurde ein Python-Skript entwickelt, das nach einer Entfernung von Stoppwörtern die Häufigkeit der fünf häufigst genannten Wörter im Text erfasst. Dabei wird die relative Häufigkeit^[Absolute Häufigkeit des Wortes dividiert durch die Gesamtzahl der Wörter des Textes multipliziert mit 100, wobei in diesem Kontext zu bemerken ist, dass die Gesamtzahl der Wörter eines Briefes und die Häufigkeit der Wörter nach Entfernung der Stoppwörter berechnet wurde. Die daraus errechnete Zahl gibt an, wie oft das betreffende Wort durchschnittlich pro 100 Wörter des Textes vorkommt. Dieses Vorgehen ermöglicht einen Vergleich der Häufigkeit von Wörtern in unterschiedlich langen Texten. Für verschiedene diesbezügliche Berechnungsarten siehe @jannidis_quantitative_2017.] des Vorkommens eines Wortes ermittelt. Eine Lemmatisierung der Wörter hat zuvor nicht stattgefunden.^[Für weiterführende Überlegungen hierzu siehe den Abschnitt [TEI text/body](#tei-textbody).]|
: Metadaten zur Briefkorrespondenz Landsbergers {#tbl-metadaten}

### Kodierung in TEI
TEI ist ein etablierter Standard für die Kodierung von geisteswissenschaftlichen Texten im Allgemeinen. Es existieren aber auch spezielle Auszeichnungsmöglichkeiten für die Textgattung Brief, um beispielsweise den Briefkopf, Gruß- und Schlussformeln und Postskripta zu kodieren. Das Element \<correspDesc\> im Header kann zudem die relevanten Metadaten erfassen, die es ermöglichen, Briefdaten aus verschiedenen Korpora miteinander zu verknüpfen.^[@matthews-schlinzig_digitalisierung_2020, 389-390.] Dementsprechend wurde gemäß den TEI Guidelines^[Das im Folgenden dargestellte Schema wurde anhand folgender Quellen erarbeitet: @dumont_correspsearch_2016; @dumont_encoding_2019; @bleier_tei_2019 sowie den Allgemeinen TEI Guidelines, [https://tei-c.org/release/doc/tei-p5-doc/en/html/index.html](https://tei-c.org/release/doc/tei-p5-doc/en/html/index.html), letzter Zugriff 30.12.2023.] auch für dieses Briefkorpus ein Schema entwickelt, um die einzelnen Briefe zu kodieren.

#### TEI Header
Die Erstellung des TEI Header für die einzelnen Briefe basiert auf der im Abschnitt [Erhebung von Metadaten](#erhebung-von-metadaten) beschriebenen Metadatentabelle. Hierzu wurde ein Python-Skript geschrieben, das die Daten aus der Metadatentabelle automatisiert in den jeweiligen Brief-Header einfügt und mit weiteren default-Angaben ergänzt.^[Für das Skript und die jeweilige Zuordnung der Angaben der Metadatentabelle zu den TEI Tags siehe [https://github.com/th-blaschke/landsberger.github.io/blob/main/files/python/create_tei_header.py](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/python/create_tei_header.py). Für ein konkretes Beispiel für einen Header siehe [https://github.com/th-blaschke/landsberger.github.io/blob/main/files/letters/tei/1929-07-10_Mueller_Landsberger.xml](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/letters/tei/1929-07-10_Mueller_Landsberger.xml).]

Eine weitere Information, die über den Rahmen dieser Arbeit hinaus in den TEI Header eingeordnet werden könnte, wäre eine Angabe dazu, wie die einzelnen Briefe in die Gesamtkorrespondenz einzubetten sind (TEI Tag \<correspContext\>).^[TEI Guidelines, [https://www.tei-c.org/release/doc/tei-p5-doc/de/html/ref-correspDesc.html](https://www.tei-c.org/release/doc/tei-p5-doc/de/html/ref-correspDesc.html), letzter Zugriff 02.01.2024.] So könnte beispielsweise angegeben werden, welcher Brief eine direkte Antwort auf einen vorangehenden Brief darstellt. In Bezug auf das hier vorgestellte Briefkorpus ist dies z.T. schwierig, da viele der Briefe isoliert dastehen. Nur die Korrespondenz zwischen Karl Friedrich Müller und Benno Landsberger liegt über einen längeren Zeitraum kontinuierlich vor, wobei sich einige Briefe zeitlich auch zu überschneiden scheinen, da die beiden in ihrem Briefaustausch nicht zwangsläufig immer auf eine Antwort des anderen gewartet haben, bevor ein neuer Brief verfasst wurde.

#### TEI text/body
Die übergeordnete Struktur des eigentlichen Brieftextes lässt sich mit folgenden Tags beschreiben, wobei diese optional sind und nicht in jedem Brief in derselben Reihenfolge und Struktur vorliegen:

|**TEI Tag**|**Attribut**|**Enthaltene Informationen**|
|---|---|---|
|**\<opener\>**|    |       |
|\<address\>|       |       |
|\<addrLine\>(\<placeName\>)|\<placeName\> enthält ein ref-Attribut mit Angabe der GeoNames ID des Ortes|Angabe der Adresse des\*r Absender\*in (vereinzelt zusätzlich auch Adresse des*r Empfänger\*in)|
|\<dateline\>\<date\>|when-Attribut mit Angabe des Datums im ISO 8601-Format|Datum der Abfassung des Briefes|
|\<persName\>|ref-Attribut mit Angabe der Wikidata ID der Person|Vereinzelt wird der Name des*r Absender\*in des Briefes im Briefkopf genannt
|   |   |   |
|\<salute\>|    |Enthält die Anredeformel (z.B. Hochverehrter Herr Professor!)|
|   |   |   |
|   |   |   |
|**\<p\>**|   |(Enthält den Kerntext des Briefes. Zu den Annotationen siehe @tbl-briefinhalte.)|   
|   |   |   |
|   |   |   |
|**\<closer\>**|    |     |
|\<salute\>|      |Enthält die Grußformel am Ende des Briefes|
|\<signed\>|    |Enthält die Unterschrift des\*r Absender\*in|
|   |   |   |
|\<postscript\>|    |     |
|\<p\>|   |Enthält den angehängten Text nach der Signatur|
: TEI Tags zur Wiedergabe der Briefstruktur

Für die Textstruktur sind zudem die Tags \<unclear\> für die Markierung von Wörtern oder Textpassagen, die nicht sicher gelesen werden können, und \<handShift\> für handschriftliche Einfügungen in den mit Schreibmaschine verfassten Briefen relevant. Randnotizen werden als \<div type=`"notes"`\> gekennzeichnet. In Fällen, in denen vorgedruckte Elemente des Briefkopfes vorliegen, wird dem entsprechenden Element-Tag das Attribut \<style=`"pre-printed"`\> hinzugefügt.^[Für eine andere Form von Annotation von vorgedruckten Briefelementen siehe auch @seifert_pre-printed_2019.]

Im Kerntext des Briefes sowie im Postskriptum können weitere Informationen kodiert werden.^[Absender\*innen und Empfänger\*innen, die in Gruß- und Schlussformel genannt werden, werden nicht noch zusätzlich ausgezeichnet und mit Normdaten versehen, da diese Informationen bereits im TEI Header vorliegen.] Dabei handelt es sich um Entitäten wie Personen, Ortsnamen, Publikationen, einzelne Keilschrifttexte und fremdsprachliche Textpassagen. Bei den Personen- und Ortsnamen wird eine Unterscheidung zwischen altorientalischen (ANE) und modernen Orten und Personen getroffen. Hierzu werden nachfolgende Tags und Attribute verwendet:

|**TEI Tag**|**Attribut**|**Enthaltene Informationen**|
|---|---|---|
|\<persName\>|type=`"modern"` oder `"ANE"`, ref-Attribut mit Angabe der Wikidata ID oder alternativ der GND ID|Personennamen|
|            |                     |
|\<placeName\>|type=`"modern"` oder `"ANE"`, ref-Attribut mit Angabe der GeoNames ID oder der Pleiades ID^[[https://pleiades.stoa.org/](https://pleiades.stoa.org/), letzter Zugriff 02.01.2024.]|Ortsnamen (es wird keine genauere Unterscheidung zwischen Stadt- und Ländernamen getroffen, da diese Unterscheidung insbesondere für altorientalische geographische Namen nicht immer eindeutig zu treffen wäre)|
|            |                     |
|\<orgName\>|type=`"university"`, `"institute"`, `"academy"` oder `"museum"` (weitere Ergänzungen möglich)|Namen von Organisation(seinheiten)
|            |                     |
|\<name\>|type=`"academicdiscipline"`, ref-Attribut mit Angabe der Wikidata ID|Name von akademischen Disziplinen (z.B. Altorientalistik, Semitistik)|
|            |                     |
|\<name\>|type=`"deity"`, ref-Attribut mit Angabe der Wikidata ID|Altorientalische Götternamen^[Prinzipiell bestünde auch die Möglichkeit, altorientalische Götternamen mit dem Tag \<persName\> und einem entsprechenden Attribut type=`"deity"` zu versehen. Da die Personifikation von Gottheiten jedoch ein strittiges Thema ist, erscheint die Wahl des generelleren \<name\>-Tags mit entsprechendem Attribut die geeignetere Wahl.]|
|            |                     |
|\<lang\>|xml:lang mit Angabe gemäß IANA^[[https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry](https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry), letzter Zugriff 02.01.2024.]|Name und Identifier einer im Text genannten Sprache|
|            |                     |
|\<foreign\>|xml:lang mit Angabe gemäß IANA|Kennzeichnung von fremdsprachlichen Textpassagen|
|            |                     |
|\<title\>|type=`"cuneiformtext"`, ref-Attribut mit Angabe der CDLI ID^[[https://cdli.mpiwg-berlin.mpg.de/](https://cdli.mpiwg-berlin.mpg.de/), letzter Zugriff 02.01.2024.]|Name eines Keilschrifttextes; dies kann sich auf einen tatsächlichen Namen, der entweder modern (z.B. "Krönungsritual") oder altorientalisch (z.B. wie die Serie *ana ittišu*) vergeben wurde, oder den Publikationsort des Keilschrifttextes (z.B. "KAR 19") beziehen|
|       |type=`"journal"` oder `"monograph"`, ref-Attribut mit Angabe der GND ID|Name eines Publikationsorts wie einer Zeitschrift, Monographie oder einer Buchreihe|
|       |type=`"meeting"`, ref-Attribut mit Angabe der GND ID|Name eines Kongresses/Konferenz|
: TEI Tags zur Annotation der Briefinhalte {#tbl-briefinhalte}

Die genannten Tags wurden manuell den Brieftexten hinzugefügt, nachdem sich verschiedene Versuche, dies automatisiert zu tun, als ineffektiv herausgestellt hatten.^[Was im Rahmen dieser Arbeit nicht getestet wurde, aber potenziell zu einer verbesserten automatisierten Annotation der Texte beitragen könnte, wäre die Nutzung von auf LLMs basierten Programmen wie ChatGPT. Für den Einsatz von ChatGPT in Editionsprojekten siehe beispielsweise die Publikationen von Christopher Pollin zu *Angewandte Generative KI in den (digitalen) Geisteswissenschaften*, [https://chpollin.github.io/](https://chpollin.github.io/), letzter Zugriff 18.02.2024.]

Zum einen wurde versucht, mithilfe der Python-Library spaCy^[[https://spacy.io/](https://spacy.io/), letzter Zugriff 02.01.2024.] eine Named Enitity Recognition durchzuführen.^[Für weitere Hintergründe und Tools für Named Entity Recognition in den Digital Humanities siehe @schumacher_named_2018.] Hierzu wurde das für die deutsche Sprache zur Verfügung stehende Modell "de_core_news" in den drei Stufen small (sm), medium (md) und large (lg) getestet.^[[https://spacy.io/models/de](https://spacy.io/models/de), letzter Zugriff 02.01.2024.] In allen drei Modellen wurden die Entitätstypen nicht korrekt zugeordnet. Beispielsweise wurden Personen- und Publikationsnamen vielfach als Ortsnamen eingestuft. Da das in spaCy zur Verfügung gestellte Modell, wie auch der Name "de_core_news" schon sagt, anhand von Nachrichtentexten trainiert wurde, war bereits anzunehmen, dass die Erkennungsrate bei Briefen nicht ebenso hoch sein würde wie bei den Textarten, auf die das Modell trainiert wurde. Die Erkennungsrate bei dem hier untersuchten Briefkorpus ist allerdings so schlecht, dass sie letztlich nicht nutzbar ist.

Bei dem Versuch, stattdessen das webbasierte Tool WebLicht^[[https://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/Main_Page](https://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/Main_Page), letzter Zugriff 02.01.2024.] für die Named Entity Recognition zu nutzen, wurde des Weiteren deutlich, dass insbesondere die in den Briefen diskutierten Begriffe aus altorientalischen Sprachen ein Problem für die Erkennung von Named Entities bedeuten, da diese fast durchgehend als Organisation oder Personennamen eingeordnet wurden. Auch mittels des Stanford Named Entity Recognizer (NER)^[[https://nlp.stanford.edu/software/CRF-NER.html#About](https://nlp.stanford.edu/software/CRF-NER.html#About), letzter Zugriff 02.01.2024.] konnten keine überzeugenden Ergebnisse erzielt werden.

Zum anderen wurde in Betracht gezogen, Named Entities automatisiert zu erkennen und im Text zu annotieren, indem ein automatisierter Abgleich zwischen vorgefertigten Listen und den Brieftexten stattfindet. Hierfür bieten sich beispielsweise die bereits beschriebenen CSV-Tabellen zu den Altorientalist\*innen in Landsbergers Zeiten und die Liste von Landsbergers Publikationen an (siehe dazu den Abschnitt [Verwendung von Normdaten](#verwendung-von-normdaten)). Aber auch hier stellen sich Herausforderungen, die die Automatisierungsmöglichkeiten des Abgleichs so stark begrenzen, dass letztlich eine von vornherein manuell durchgeführte Annotation in einer schnelleren Zeit durchgeführt werden kann. Als Beispiel sei hier der Altorientalist Hans-Siegfried Schuster genannt, der in einer Reihe von Briefen, die zwischen Karl Friedrich Müller und Landsberger ausgetauscht wurden, thematisiert wird. Landsberger kürzt den Namen Schusters häufig als S. oder Sch. ab. Die Abkürzung S. taucht in den Briefen gleichzeitig aber auch als Abkürzung für Seite auf, wenn über Publikationen gesprochen wird und ist somit nicht eindeutig. Auch der Spitzname Walti für Walter G. Kunstmann taucht in den Briefen auf und ließe sich nicht ohne Weiteres durch eine Liste mit offiziellen Namen abgleichen. Einige zu Lebzeiten Landsbergers von Deutschlands aus in die USA emigrierte Wissenschaftler\*innen veränderten zudem ihre Namensschreibungen in Bezug auf Umlaute. So findet sich beispielsweise sowohl die Schreibung Götze als auch Goetze für einen Kollegen Landsbergers. Ambivalenzen finden sich auch bei Ortsnamen. Beispielsweise trägt der Hauptgott der altorientalischen Stadt Assur ebenfalls den Namen Assur. Eine Unterscheidung von Gottes- und Stadtname in der Annotierung erfordert ebenfalls einen manuellen Abgleich. Akkad. stellt eine Abkürzung für die Sprache Akkadisch dar. In Fällen, in denen der Punkt hinter der Abkürzung weggelassen oder für eine vereinfachte automatisierte Texterkennung die Satzzeichen eines Textes entfernt wurden, besteht bei einem automatisierten Abgleich eine Verwechslungsgefahr mit dem Ortsnamen Akkad. Sicherlich besteht die Möglichkeit, für die hier genannten Ausnahmefälle mithilfe eines Programmierskriptes automatisierte Lösungen zu finden. Der hierfür nötige Arbeitsaufwand ist realistischerweise aber eher von einem größeren Projektteam zu leisten und nicht in einer kleiner angelegten Edition möglich. Gleichzeitig ist zu bemerken, dass die Annotation der Texte Fachkenntnisse in der Altorientalistik bedarf, um ambivalente Begriffe unterscheiden zu können.

Während die Annotation von Named Entities, sei es automatisiert oder manuell, durch ein recht klar definiertes Tag-Set ermöglicht wird, stellt die Annotation von Aussagen und Sinnstrukturen in den Briefen eine weitaus größere Herausforderung dar. Einen Versuch, eine inhaltliche Zusammenfassung und grundlegende Schlagwörter herauszuarbeiten, die den Inhalt eines Briefes prägen, stellt die Identifizierung der häufigsten Wörter eines Briefes dar, wie sie in der Metadatentabelle in der Spalte "Häufigste Wörter (Relative Häufigkeit)" geschehen ist (siehe @tbl-metadaten). Um die errechnete relative Häufigkeit der jeweils häufigsten Wörter pro Brief noch deutlicher in Relation mit dem Gesamtbriefkorpus zu setzen, wurde zusätzlich in Form einer Term-Dokument-Matrix das Vorkommen dieser Wörter in jedem Einzelbrief dargestellt.^[[https://github.com/th-blaschke/landsberger.github.io/blob/main/files/term_document_matrix.csv](https://github.com/th-blaschke/landsberger.github.io/blob/main/files/term_document_matrix.csv).] In der für diese Arbeit erstellten digitalen Edition der Briefe wird zudem für jeden einzelnen Brief die Möglichkeit gegeben, einen Ausschnitt der Term-Dokument-Matrix anzusehen, der anzeigt, in welchen anderen Briefen die fünf ermittelten häufigsten Stichwörter ebenfalls vorkommen.^[Für den Brief von Karl Friedrich Müller an Benno Landsberger vom 07.10.1929 siehe beispielsweise folgende Häufigkeitstabelle: [https://th-blaschke.github.io/landsberger.github.io/1929-07-10_Mueller_Landsberger_wordfrequency.html](https://th-blaschke.github.io/landsberger.github.io/1929-07-10_Mueller_Landsberger_wordfrequency.html). Für die CSV-Dateien für die Einzeltexte siehe [https://github.com/th-blaschke/landsberger.github.io/tree/main/files/wordfrequency](https://github.com/th-blaschke/landsberger.github.io/tree/main/files/wordfrequency).] Theoretisch dürfte diese Form von Verknüpfung auch die Auffindung von thematisch ähnlichen Briefen ermöglichen. Bezüglich dieses Vorgehens lassen sich aber auch einige Kritikpunkte finden. Zum einen hat vorab keine Lemmatisierung stattgefunden, so dass sich Wörter desselben Wortstammes gleichzeitig unter den fünf häufigsten Wörtern befinden können. So findet sich beispielsweise in dem am 10.07.1927 von Karl Friedrich Müller an Landsberger verfassten Brief unter den fünf häufigsten Wörtern sowohl Assur als auch die Genitivform Assurs.^[Siehe [https://th-blaschke.github.io/landsberger.github.io/1929-07-10_Mueller_Landsberger.html](https://th-blaschke.github.io/landsberger.github.io/1929-07-10_Mueller_Landsberger.html).] Eine manuelle Korrektur und Zusammenfassung dieser Wortformen ist in einem kleinen zu bearbeitenden Textkorpus sicherlich durchführbar, wird aber mit größeren Textmengen ein bedeutender Aufwand. Der Versuch, eine Lemmatisierung der Texte des Briefkorpus mit der bereits oben beschriebenen Python-Library spaCy und den zugehörigen drei Modellen für die deutsche Sprache durchzuführen, hat allerdings ähnlich wie bei der Named Entity Recognition zu einer Anzahl von Fehlern geführt, die nicht akzeptabel erschien. Verschiedene Begriffe wurden nicht korrekt ihrer Grundform zugeordnet. Beispielsweise wurde der Plural Assistentenstellen auf "Assistentenstell" zurückgeführt, Babylonien zu "Babylonie" gemacht, der Personenname von Soden zu "Sode". Stattdessen ein Topic Modeling^[@horstmann_topic_2018.] durchzuführen, um inhaltliche Zusammenhänge zwischen den Thematiken der Briefe zu entdecken, war ebenfalls erfolglos. Topic Modeling als eine Methode des unüberwachten Machine Learning ist auf größere Textmengen ausgerichtet als das vorliegende Textkorpus sie bietet und hat daher nur indifferente Ergebnisse geliefert.^[Es wurde hierfür der DARIAH Topic Explorer genutzt, [https://de.dariah.eu/topicsexplorer](https://de.dariah.eu/topicsexplorer), letzter Zugriff 02.01.2024. Es wurden 1000 Iterationen bei 8 Topics durchgeführt.] Zum anderen stellt sich die Frage, inwieweit die häufigsten Wörter eines Textes eine prägnante Zusammenfassung seines Inhalts ermöglichen. Eine semantische Ähnlichkeit von Begriffen wird bei dieser Vorgehensweise nicht berücksichtigt. Schlagwörter, die den Inhalt eines Briefes charakterisieren, könnten stattdessen auch identifiziert werden, indem ein Kategoriensystem zur Auszeichnung der Inhalte entwickelt wird. Digitale Editionsprojekte folgen dabei unterschiedlichen Vorgehensweisen. Thematische Wortfelder können zum einen aus den zu analysierenden Texten, zum anderen unabhängig vom konkreten textuellen Forschungsgegenstand generiert werden.^[@vauth_generierung_2019.] Im bislang unpublizierten Projekt "Vernetzte Korrespondenzen | Exilnetz33"^[[https://tcdh.uni-trier.de/de/projekt/vernetzte-korrespondenzen-exilnetz33](https://tcdh.uni-trier.de/de/projekt/vernetzte-korrespondenzen-exilnetz33), letzter Zugriff 04.02.2024.] wurde ein auf das Themenfeld "Exil" zugeschnittener Thesaurus erstellt. Die in den Briefen erwähnten Wörter wurden lemmatisiert und einem Part-of-Speech-Tagging unterzogen. Nach einer Ermittlung der Häufigkeit von Einzelwörtern in den Einzelbriefen und in Relation zum Gesamtkorpus wurden diese mit einem passenden Schlagwort des Exil-Thesaurus verknüpft bzw. bei Bedarf ein neues Schlagwort erstellt. Auch wenn dieses Vorgehen halbautomatisiert geschieht, wird die Entwicklung des Thementhesaurus als ein aufwendiger Prozess beschrieben.^[@hildenbrandt_im_2014; @biehl_exilnetz33_2015.] Ein Kategoriensystem, sei es in Form eines Thesaurus oder eine Ontologie, dessen Ober- und Unterbegriffe sprachwissenschaftlich auch als Frames bezeichnet werden, schematisiert das in einer Gruppe von Texten transportierte Wissen. Es muss derart gestaltet sein, dass es eine Erschließungstiefe ermöglicht, die der an die Texte gestellten Forschungsfrage gerecht wird, es muss jedem Einzeltext der Textgruppe gerecht werden, es muss Eindeutigkeit bieten und so transparent dokumentiert sein, dass es für alle Nutzer\*innen verständlich wird.^[Zum Thema Frames siehe @strobel_digitale_2014, 155-160; @matthews-schlinzig_welchen_2018, 102-105.] Die Entwicklung so eines Kategoriensystems ist aufgrund des Aufwands der Umsetzung im Rahmen dieser Arbeit nicht geschehen, wäre für einen weiteren Ausbau der Briefedition jedoch ein erstrebenswertes Ziel.
<br/>
<br/>
<br/>
*Zitiervorschlag: Editionsprinzipien. In: Blaschke, Theresa. Die wissenschaftliche Korrespondenz Benno Landsbergers - Eine Fallstudie. Marburg 2024. https://th-blaschke.github.io/landsberger.github.io/1937-04-12_Castellino_Landsberger.html.*